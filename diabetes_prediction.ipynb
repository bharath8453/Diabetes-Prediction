###### step 1 load the dataset using pandas library
# import the pandas library
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
df=pd.DataFrame()
df
df=pd.read_excel('pima-data.xlsx')
df
pd.set_option('display.max_rows',None)
df
df.size
df.isnull().values.any()
# find corrleation b/w the columns 
# removing duplicate values
def plot_corr(df,size=12):
    corr=df.corr()
    fig, ax= plt.subplots(figsize=(12,12))
    cmap='plasma'
    ax.matshow(corr,cmap=cmap)
    plt.xticks(range(len(corr.columns)), corr.columns,rotation=20)
    plt.yticks(range(len(corr.columns)), corr.columns)
    plt.show()
plot_corr(df)
corr=df.corr()
corr
df.drop('thickness',axis=1,inplace=True)
df.drop('has_diabetes',axis=1,inplace=True)
df.drop('diabetes_orig',axis=1,inplace=True)
df
df.head()
# convert text into integer
# creating a dictionary to convert true to 1 and false to 0
# want to replace true and false in diabetes columns

dict1={
    'diabetes':[True ,False]
}
dict2={
    'diabetes':[1,0]
}
df.replace(dict1,dict2,inplace=True)
df.head()
num_true= len(df.loc[df['diabetes']==1])
num_true
num_true= len(df.loc[df['diabetes']==1])
num_false= len(df.loc[df['diabetes']==0])
print(f'num_true={num_true}')
print(f'num_false={num_false}')
per_num_true= (num_true / (num_true+num_false) )*100
print(per_num_true)
per_num_false= (num_false / (num_false+num_true))*100
print(per_num_false)
# train_split_test
pip install scikit-learn
import sklearn
print("scikit-learn version:", sklearn.__version__)
df.columns
from sklearn.model_selection import train_test_split
input_columns=['num_preg', 'glucose_conc', 'diastolic_bp', 'insulin','bmi','diab_pred','age','skin','diabetes']
output_columns=['diabetes']
x = df[input_columns].values
y = df[output_columns].values

split_test_size = 0.3

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=split_test_size,random_state=42)
x
y
split_test_size=0.3

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=split_test_size,random_state=42)

print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)
print('{0:0.2f}% in training set'.format((len(x_train)/len(df.index))*100))
print('{0:0.2f}% in training set'.format((len(x_test)/len(df.index))*100))
print('{0:0.2f}% in training set'.format((len(x_train)/len(df.index))*100))
print('{0:0.2f}% in training set'.format((len(x_test)/len(df.index))*100))
print('train true: {0} ({1:0.2f}%)'.format(len(y_train[y_train[:]==1]),
                          len(y_train[y_train[:]==1])/len(y_train)*100))

print('train false: {0} ({1:0.2f}%)'.format(len(y_train[y_train[:]==0]),
                          len(y_train[y_train[:]==0])/len(y_train)*100))

print('test true: {0} ({1:0.2f}%)'.format(len(y_test[y_test[:]==1]),
                          len(y_test[y_test[:]==1])/len(y_train)*100))

print('test false: {0} ({1:0.2f}%)'.format(len(y_test[y_test[:]==0]),
                          len(y_test[y_test[:]==0])/len(y_train)*100))
# post split preparation
total_num_preg= len(df.loc[df['num_preg']==0])
print(f' number of rows missing in num_preg column is {total_num_preg}' )

total_glucose_conc= len(df.loc[df['glucose_conc']==0])
print(f' number of rows missing in glucose_conc column is {total_glucose_conc}' )

total_diastolic_bp= len(df.loc[df['diastolic_bp']==0])
print(f' number of rows missing in diastolic_bp column is {total_diastolic_bp}' )

total_insulin= len(df.loc[df['insulin']==0])
print(f' number of rows missing in insulin column is {total_insulin}' )

total_bmi= len(df.loc[df['bmi']==0])
print(f' number of rows missing in bmi column is {total_bmi}' )

total_diab_pred= len(df.loc[df['diab_pred']==0])
print(f' number of rows missing in diab_pred column is {total_diab_pred}' )

total_age= len(df.loc[df['age']==0])
print(f' number of rows missing in agecolumn is {total_age}' )

total_skin=len(df.loc[df['skin']==0])
print(f' number of rows missing in skincolumn is {total_skin}' )

df
df.columns
from sklearn.impute import SimpleImputer
fill_0=SimpleImputer(missing_values=0,strategy='mean')
x_train=fill_0.fit_transform(x_train)
x_test=fill_0.fit_transform(x_test)
x_train[0:3]
scaler=StandardScaler()
x_train=scaler.fit_transform(x_train)
x_test=scaler.transform(x_test)
# training the model# using Naive Bayes algorithm
from sklearn.naive_bayes import GaussianNB

nb_model = GaussianNB() #creating object for gussian 
nb_model.fit(x_train,y_train.ravel()) #training the model 
from sklearn import metrics
nb_predict_model=nb_model.predict(x_train)
print(f'predictted data {metrics.accuracy_score(y_train,nb_predict_model)}')
nb_predict_test=nb_model.predict(x_test)
print(f'predictted data {metrics.accuracy_score(y_test,nb_predict_test)}')
print('confussion matrics')
print(f'{metrics.confusion_matrix(y_test,nb_predict_test)}')
print('classifiction')
print(metrics.classification_report(y_test,nb_predict_test))
# training the random forest
from sklearn.ensemble import RandomForestClassifier
rf_model=RandomForestClassifier(random_state=42)
rf_model.fit(x_train,y_train.ravel())
rf_predict_model=rf_model.predict(x_train) # train the model
print(f'predictted data {metrics.accuracy_score(y_train,rf_predict_model)}') #accuracy
rf_predict_test=rf_model.predict(x_test)
print(f'predictted data {metrics.accuracy_score(y_test,rf_predict_test)}')
print('confussion matrics')
print(f'{metrics.confusion_matrix(y_test,rf_predict_test)}')
print('classifiction')
print(metrics.classification_report(y_test,rf_predict_test))
# training the kmeighbour 
from sklearn.neighbors import KNeighborsClassifier
k_neighbor=KNeighborsClassifier()
k_neighbor.fit(x_train,y_train.ravel())
kf_predict_model=k_neighbor.predict(x_train)
print(f'predictted data {metrics.accuracy_score(y_train,kf_predict_model)}')
kf_predict_test=k_neighbor.predict(x_test)
print(f'predictted data {metrics.accuracy_score(y_test,kf_predict_test)}')
print('confussion matrics')
print(f'{metrics.confusion_matrix(y_test,kf_predict_test)}')
print('classifiction')
print(metrics.classification_report(y_test,kf_predict_test))
input_data=[1,85,66,0,26.6,0.351,31,1.1426,0]
input_array=np.asarray(input_data).reshape(1,-1)
input_array=fill_0.transform(input_array)
print(input_array)
input_array=scaler.transform(input_array)
print(input_array)
prediction=rf_model.predict(input_array)
print("prediction:","diabetics" if prediction[0] ==1 else "not diabetics")
import pickle
# save the model
with open ('rf_model.pkl','wb')as f :
   pickle.dump(rf_model, f)
#save scaler
with open ('scaler.pkl','wb')as f :
   pickle.dump(scaler, f)
#save imputer
with open ('imputer.pkl','wb')as f :
   pickle.dump(fill_0, f)
